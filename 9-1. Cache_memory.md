### 캐시 기억장치
- 캐시 기억장치
  - 목적
    - CPU와 주기억장치 속도 차이로 인해 CPU 대기 시간 최소화를 위해 CPU와 주기억장치 사이에 설치함.
    - 보통 SRAM을 많이 쓴다. 주기억장치는 DRAM을 많이 씀. DRAM의 속도가 느린 것을 보완
  - 특징
    - 주기억장치보다 엑세스 속도가 높은 칩 사용
    - 가격 및 제한된 공간 때문에 용량이 적음
  - 용어
    - 캐시 적중(cache hit) : CPU가 원하는 데이터가 캐시에 있는 상태
    - 캐시 미스(cache miss) : CPU가 원하는 데이터가 캐시에 없는 상태. 이 경우 주기억장치로부터 데이터를 읽음
    - 적중률(hit ratio) : 캐시에 적중되는 정도(H)
      - H = 캐시에 적중되는 횟수 / 전체 기억장치 엑세스 횟수
      - HIT율이 높으면 그만큼 성능이 상승되는 것이다.
    - 캐시의 미스율(miss ratio) = 1- H
    - 평균 기억장치 엑세스 시간(Ta)
      - Ta = H * Tc + (1 - H) * Tm
      - Tc : 캐시 엑세스 시간, Tm : 주기억장치 엑세스 시간
    - ![Alt text](/images/9-1-0.png)
    - 지역성
      - 시간적 지역성(temporal locality) : 최근에 엑세스된 프로그램이나 데이터가 가까운 미래에 다시 엑세스 될 가능성이 높음
      - 공간적 지역성(spatial ~) : 기억장치내에 인접해 저장되어 있는 데이터들이 연속적으로 엑세스 될 가능성이 높음
      - 순차적 지역성(sequential) : 분기가 발생하지 않는 한, 명령어들은 기억장치에 저장된 순서대로 인출되어 실행됨(즉, 순서대로 fetch)
  - 캐시 설계 목표
    - 적중률 극대화
    - 캐시 엑세스 시간의 최소화
    - 캐시 미스에 따른 지연 시간 최소화
    - 주기억장치와 캐시간의 데이터 일관성 유지 및 그에 따른 오버헤드의 최소화
      - 데이터 일관성이라는 것은 주기억장치와 캐시 메모리의 내용이 일치해야 한다는 것이다. 왜냐면 주기억장치 내용이 복사되어 캐시에 유지되기 때문인데, CPU에 의해 캐시 내용이 갱신되면 내용이 달라지니까 그것을 유지하기 위한 장치가 필요하다.
      - 그런 작업을 할 경우 시간 손실 등 여러 오버헤드가 발생할 수 있다. 그것을 최소화 해야 한다.
  - 캐시의 크기
    - 용량이 커질수록 적중률 높지만, 비용 증가
    - 용량이 커질수록 주소 해독 및 정보 인출을 위한 주변 회로가 더 복잡해져 엑세스 시간이 조금 더 길어짐(큰 문제는 아님)
  - 인출 방식
    - 요구 인출(demand fetch) 방식 : 필요한 정보만 인출해 오는 방법
      - 즉, 필요할 때마다 요청하기 때문에 속도가 좀 느려질 수 있다.
    - 선인출(prefetch) 방식
      - 필요 정보 외에 앞으로 필요할 것으로 예측되는 정보 미리 인출
      - 지역성이 높은 경우 효과가 높음(hit율을 높일 수 있다.)
  - 주기억장치와 캐시의 조직
    - 주기억장치 블록 전체 -> 캐시 라인에 적재
    - 해당 라인이 여러개 있으며 블록 단위로 이동하여 히트율을 높일 수 있다.
    - ![Alt text](/images/9-1-1.png)
    - 블록(block) : 주기억장치로부터 동시에 인출되는 정보들의 그룹
      - 주기억장치 용량 = 2^n 단어, 블록 = k단어
        - 블록의 수 = 2^n / k 개
    - 라인(line, slot) : 캐시에서 한 블록이 저장되는 장소
    - 태그(tag) : 라인에 적재된 블록을 구분하는 정보(주기억장치의 내용이 캐시의 어느 라인의 어디에 있는지 알 수 있도록 하기 위함)
  - 사상 방식
    - 주기억장치 블록이 어느 캐시 라인을 공유할 것인 지를 결정하는 방법
    - 직접 사상(direct mapping) 
      - 주기억장치의 블록이 지정된 하나의 캐시 라인으로만 적재
      - ![Alt text](/images/9-1-2.png)
      - 주기억장치의 블록 j 가 적재될 수 있는 캐시 라인의 번호 i
        - i = j mod m
        - 단, j : 주기억장치 블록 번호, m : 캐시 라인의 전체 수
      - 각 캐시 라인은 2^t 개의 블록들에 의해 공유됨. 같은 라인을 공유하는 블록들은 서로 다른 태그를 가짐
        - ![Alt text](/images/9-1-3.png)
        - m개의 캐시라인이 있다면 0은 0에 m-1은 m-1에 mapping되고 m은 다시 0을 공유함.
        - 그래서, 동시에는 사용 못하고, 한 시점에서는 한 개의 주기억장치 블록이 하나의 캐시 라인만 사용할 수 있다.
      - 동작 원리
        - 캐시로 기억장치 주소가 보내지면, 그 중 s-비트의 라인 번호를 이용해 캐시의 라인 선택
        - 선택된 라인의 태그 비트를 읽어서 주소의 태그 비트와 비교
          - 두 태그 일치시 : 캐시 적중 - 주소의 w비트를 이용해 라인 내의 단어들 중 하나 인출해 cpu로 전송
          - 일치 않는다면 : 캐시 미스
            - 주소를 주기억장치로 보내 한 블록 엑세스
            - 인출된 블록을 지정된 캐시 라인에 적재하고, 주소의 태그 비트들을 그 라인의 태그 필드에 기록
            - 만약 그 라인에 다른 블록이 이미 적재시, 그 내용은 지우고 새로이 인출된 블록 적재
      - 장단점
        - 하드웨어 간단, 구현 비용 적음
        - 각 주기억장치 블록이 적재될 수 있는 캐시 라인이 한 개라서 히트율이 줄어들게 된다.
      - 예
        - ![Alt text](/images/9-1-4.png)
          - 주소가 128개의 주소가 있는 것이고, 주소를 표현하기 위해 7비트의 주소가 필요함.
          - 블록 크기는 4바이트이므로 128/4 = 32개의 블록임
          - 한 블록이 한 라인과 같아야 함. 즉, 한 라인이 4바이트이고 전체 라인의 수는 32/4 = 8개이다.
          - 라인이 8개니까 2^3이므로 3비트, 워드는 블록이 4바이트니까 2비트, 나머지 태그는 2비트 : 전체 주소 7비트
          - ![Alt text](/images/9-1-5.png)
            - 뒤의 2개의 워드 비트는 생략됨. 하나의 라인으로 이동하므로 중요한 정보가 아님.
            - 파란색이 결국 라인의 번호가 됨. 같은 라인의 번호를 가진 블록들이 하나의 캐시 라인을 공유하는 것.
            - 1: 4로 매핑되며 좌측이 1이면 직접사상인 것.
          - ![Alt text](/images/9-1-6.png)
          - 그렇다면, 매핑이 4개씩 되면 어느 정보가 현재 캐시에 있는지 어떻게 아는가? 그것은 라인을 알아냈으면 태그를 비교해 해당 태그의 값에 따라 어느 정보가 있는지 알 수 있는 것이다.
    - 완전 연관사상(fully-associative ~)
      - 구현이 매우 어려움, 주기억장치 블록이 캐시의 어떤 라인으로든 적재 가능, 태그 필드 = 주기억장치 블록 번호
      - ![Alt text](/images/9-1-7.png)
        - 라인 번호가 없다. 왜냐면 어떤 라인에도 적재 가능하기 때문. 
        - 그래서 태그를 일일이 다 비교하여야 한다. 라인이 많아지면 비교 회로가 너무 복잡해지기에 구현이 힘든 것이다.
      - 장점
        - 새로운 블록이 캐시 적재시 라인 선택이 자유로움
        - 지역성이 높다면, 적중률 매우 높음
      - 단점
        - 태그를 병렬로 검사하기 위해 가격이 높은 연관 기억장치 및 복잡한 주변 회로 필요
      - ![Alt text](/images/9-1-8.png)
        - 이에 따라, 어느 위치에 있든 간에 다 쓸 수 있다.
    - 세트 연관사상(set-associative ~)
      - 실제 사용되는 방식
      - 직접 사상과 완전연관 사상의 조합
      - 주기억장치 블록 그룹이 하나의 캐시 세트를 공유하며, 그 세트에는 두 개 이상의 라인이 적재가능
      - 캐시는 v 개의 세트로 나뉘며, 각 세트는 k개의 라인으로 구성
      - 캐시 라인의 수 m과 주기억장치 블록이 적재될 수 있는 캐시 세트 번호 : m = v * k, i = j mod v
        - i : 캐시 세트 번호, j : 주기억장치 블록 번호, m : 캐시 라인 수
      - 기억장치 주소 형식
        - ![Alt text](/images/9-1-9.png)
        - 세트 번호로 지정, 라인 번호가 아님. 세트 내부에 여러 라인 있음
        - 즉, 세트 속 라인 수 1개면 직접 사상, 전체 라인 개수를 모두 포함시 완전 연관 사상, 그루핑한 경우 세트연관 사상
      - 동작 원리
        - 기억장치 주소의 세트 비트들을 이용해 캐시 세트들 중 하나를 선택
        - 주소의 태그 필드 내용과 그 세트내의 태그들을 비교
          - 일치시 : 캐시 적중
            - 그 라인내의 한 단어를 w 비트에 의해 선택해 인출
          - 일치 않는다면 : 캐시 미스
            - 주기억장치 엑세스
            - 라인중 어느 라인에 새로운 블록 적재할 것인지 결정해 교체(교체 알고리즘 사용)
          - ![Alt text](/images/9-1-10.png)
          - ![Alt text](/images/9-1-11.png)
          - 'abcd'는 태그 000과 010 두개의 라인 중에 하나에 들어갈 수 있는 것이다.
          - ![Alt text](/images/9-1-12.png)
            - 바이트 단위 주소 지정이라는 것은 하나의 주소에 1바이트 저장
            - 그리고 2개씩 라인을 지정시에는 2^13개의 세트가 되는 것.
            - 1set = 2line이면 2way 세트 연관사상이 되는 것이다.
          - ![Alt text](/images/9-1-13.png)
      - 세트 연관 사상은 2, 4, 8씩 way를 높일 수록(연관도가 높을 수록), 즉 세트가 커질 수록 미스율이 낮아진다.
